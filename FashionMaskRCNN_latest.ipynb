{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snvssk/data255/blob/main/FashionMaskRCNN_latest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB_y-tO1MNsG"
      },
      "source": [
        "# Importing Libraries "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uGpBnlBBJOI"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gc\n",
        "import sys\n",
        "import json\n",
        "import random\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "import cv2 # CV2 for image manipulation\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from imgaug import augmenters as iaa\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# import tensorflow as tf\n",
        "# tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "# import keras\n",
        "# import keras.engine\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3K-H5UteCVq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = Path('/content/drive/Shareddrives/DATA-255/Datasets')\n",
        "ROOT_DIR = Path('/content')"
      ],
      "metadata": {
        "id": "o9F_V611CYBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/Shareddrives/DATA-255/Datasets/label_descriptions.json') as file:\n",
        "    label_d = json.load(file)\n",
        "\n",
        "\n",
        "sample_sub_df = pd.read_csv('/content/drive/Shareddrives/DATA-255/Datasets/sample_submission.csv')\n",
        "train_df = pd.read_csv('/content/drive/Shareddrives/DATA-255/Datasets/train.csv')"
      ],
      "metadata": {
        "id": "tHe4ah5iCZcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Label description columns {}\".format(list(label_d.keys())))"
      ],
      "metadata": {
        "id": "oq3U0hvD_2An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate label description into categories and attributes\n",
        "categories_df = pd.DataFrame(label_d['categories'])\n",
        "attributes_df = pd.DataFrame(label_d['attributes'])\n"
      ],
      "metadata": {
        "id": "22_S8D30_6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categories_df"
      ],
      "metadata": {
        "id": "y4NL_efo_6Lm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "categ_names = categories_df[\"name\"].unique()\n",
        "print(categ_names)\n",
        "print(f\"Number of attributes {len(categ_names)}\")\n"
      ],
      "metadata": {
        "id": "tnGVZAaF_6Od"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attributes\n",
        "pd.set_option('display.max_rows', 500)\n",
        "attributes_df"
      ],
      "metadata": {
        "id": "DZO8tHhx_6Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attr_names = attributes_df[\"name\"].unique()\n",
        "print(attr_names)\n",
        "print(f\"Number of attributes {len(attr_names)}\")"
      ],
      "metadata": {
        "id": "PL0VLz5M_6Ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dictionaries to map the IDs with the category and attributes strings\n",
        "cat_map = {category[\"id\"]: category[\"name\"] for category in label_d['categories']}\n",
        "cat_map_inv = {category[\"name\"]: category[\"id\"] for category in label_d['categories']}\n",
        "\n",
        "attr_map = {category[\"id\"]: category[\"name\"] for category in label_d['attributes']}\n",
        "attr_map_inv = {category[\"name\"]: category[\"id\"] for category in label_d['attributes']}"
      ],
      "metadata": {
        "id": "EHn7oyu4_6of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_raw_segmented_image(df, figsize=(15,15)):\n",
        "    # Read random image\n",
        "    random_id = df.sample()[\"ImageId\"].item()\n",
        "    image = mpimg.imread(f'/content/drive/Shareddrives/DATA-255/Datasets/train/{random_id}.jpg')\n",
        "    shape = image.shape,\n",
        "    encoded_pixels = df[train_df['ImageId'] == random_id]['EncodedPixels']\n",
        "    class_ids = df[train_df['ImageId'] == random_id]['ClassId']\n",
        "    \n",
        "    # Create mask\n",
        "    height, width = shape[0][:2]\n",
        "    mask = np.zeros((height, width)).reshape(-1)\n",
        "    for pixels, class_id in zip(encoded_pixels, class_ids):\n",
        "        pixels_split = list(map(int, pixels.split()))\n",
        "        pixel_starts = pixels_split[::2]\n",
        "        run_lengths = pixels_split[1::2]\n",
        "        for pixel_start, run_length in zip(pixel_starts, run_lengths):\n",
        "            mask[pixel_start:pixel_start + run_length] = 255 - class_id * 4\n",
        "    mask = mask.reshape(height, width, order='F')    \n",
        "    \n",
        "    # Plot images\n",
        "    fig, axs = plt.subplots(1, 2,figsize=(15,15))\n",
        "    axs[0].imshow(image)    \n",
        "    axs[1].imshow(image)    \n",
        "    axs[1].imshow(mask, alpha=0.8)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "c6L1XWYi_2GG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size = 3\n",
        "for _ in range(size):\n",
        "    plot_raw_segmented_image(train_df, \"ImageId\")"
      ],
      "metadata": {
        "id": "IwcrkbyYDgZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_classes_image(df, figsize=(15,15)):\n",
        "    # Select random image\n",
        "    random_id = df.sample()[\"ImageId\"].item()\n",
        "    image = mpimg.imread(f'/content/drive/Shareddrives/DATA-255/Datasets/train/{random_id}.jpg')\n",
        "    shape = image.shape,\n",
        "    encoded_pixels = df[train_df['ImageId'] == random_id]['EncodedPixels']\n",
        "    class_ids = df[train_df['ImageId'] == random_id]['ClassId']\n",
        "    \n",
        "    # Create mask and plot every specific class in the image\n",
        "    height, width = shape[0][:2]\n",
        "    for pixels, class_id in zip(encoded_pixels, class_ids):\n",
        "        mask = np.zeros((height, width)).reshape(-1)\n",
        "        pixels_split = list(map(int, pixels.split()))\n",
        "        pixel_starts = pixels_split[::2]\n",
        "        run_lengths = pixels_split[1::2]\n",
        "        for pixel_start, run_length in zip(pixel_starts, run_lengths):\n",
        "            mask[pixel_start:pixel_start + run_length] = 255 - class_id * 4\n",
        "        mask = mask.reshape(height, width, order='F')\n",
        "        \n",
        "        # Plot masked image\n",
        "        plt.figure(figsize=(15, 15))\n",
        "        plt.title(cat_map[class_id])\n",
        "        plt.imshow(image)    \n",
        "        plt.imshow(mask, alpha=0.8)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "PP0Uy7CNDjC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_classes_image(train_df)"
      ],
      "metadata": {
        "id": "N0A0TOZNELGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace ClassId for class string \n",
        "train_df['ClassId'] = train_df['ClassId'].map(cat_map)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "Dh2-MgggESr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot class value count\n",
        "train_df['ClassId'].value_counts()[:20].plot(kind='barh')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "DAvZ8EA0FSPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform ClassId back to int to perform the training\n",
        "train_df['ClassId'] = train_df['ClassId'].map(cat_map_inv)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "FCn7tZ7zFV0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q cython pyyaml"
      ],
      "metadata": {
        "id": "oLHRvtWuFZI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml\n"
      ],
      "metadata": {
        "id": "2UUH8U_lI5YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycocotools==2.0.2\n"
      ],
      "metadata": {
        "id": "7V2KyRdVH8P_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'git+https://github.com/facebookresearch/detectron2.git'\n"
      ],
      "metadata": {
        "id": "KIZ5oHhcH-N8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
        "from detectron2.structures import BoxMode"
      ],
      "metadata": {
        "id": "RjoCa_CaIFdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_file = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"\n",
        "cfg = get_cfg()\n",
        "cfg"
      ],
      "metadata": {
        "id": "bkS-CKChILmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.merge_from_file(model_zoo.get_config_file(config_file))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_file)\n",
        "\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "metadata": {
        "id": "gcDWe65wKnqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot images classified by the pretrained detectron\n",
        "rows, cols = 2, 2\n",
        "plt.figure(figsize=(20, 20))\n",
        "\n",
        "for i in range(int(rows * cols)):\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    \n",
        "    # Get random image\n",
        "    random_id = train_df.sample()[\"ImageId\"].item()\n",
        "    im = mpimg.imread(f'/content/drive/Shareddrives/DATA-255/Datasets/train/{random_id}.jpg')\n",
        "    height, width = im.shape[:2]\n",
        "    \n",
        "    # Get detectron prediction from the selected image\n",
        "    outputs = predictor(im)\n",
        "    \n",
        "    # Create visualizer\n",
        "    visualizer = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=0.4)\n",
        "    \n",
        "    # Change font size for better reading\n",
        "    visualizer._default_font_size = np.sqrt(height * width) // 20\n",
        "    visualizer = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    \n",
        "    # Plot images\n",
        "    plt.axis('off')\n",
        "    plt.imshow(visualizer.get_image()[:, :, ::-1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "to65ICugJ2aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rle_decode_string(string, h, w):\n",
        "    \"\"\"\n",
        "    Transforms rle string into a pixel mask\n",
        "    \n",
        "    :param string: rle string to transform into mask\n",
        "    :type string: str\n",
        "    :param string: image height\n",
        "    :type string: int\n",
        "    :param string: image width\n",
        "    :type string: int\n",
        "    :return: image mask\n",
        "    :rtype: numpy array\n",
        "\n",
        "    \"\"\"\n",
        "    mask = np.full(h * w, 0, dtype=np.uint8)\n",
        "    annotation = [int(x) for x in string.split(' ')]\n",
        "    for i, start_pixel in enumerate(annotation[::2]):\n",
        "        mask[start_pixel: start_pixel + annotation[2 * i + 1]] = 1\n",
        "    mask = mask.reshape((h, w), order='F')\n",
        "    return mask\n",
        "\n",
        "def rle2bbox(rle, shape):\n",
        "    '''\n",
        "    Get a bbox from a mask which is required for Detectron 2 dataset\n",
        "    :param rle: run-length encoded image mask, as string\n",
        "    :type rle: str\n",
        "    :param shape: (height, width) of image on which RLE was produced\n",
        "    :type rle: tuple\n",
        "    :return: (x0, y0, x1, y1) tuple describing the bounding box of the rle mask\n",
        "    :rtype: tuple\n",
        "    '''\n",
        "    \n",
        "    a = np.fromiter(rle.split(), dtype=np.uint)\n",
        "    a = a.reshape((-1, 2))  # an array of (start, length) pairs\n",
        "    a[:,0] -= 1  # `start` is 1-indexed\n",
        "    \n",
        "    y0 = a[:,0] % shape[0]\n",
        "    y1 = y0 + a[:,1]\n",
        "    if np.any(y1 > shape[0]):\n",
        "        # got `y` overrun, meaning that there are a pixels in mask on 0 and shape[0] position\n",
        "        y0 = 0\n",
        "        y1 = shape[0]\n",
        "    else:\n",
        "        y0 = np.min(y0)\n",
        "        y1 = np.max(y1)\n",
        "    \n",
        "    x0 = a[:,0] // shape[0]\n",
        "    x1 = (a[:,0] + a[:,1]) // shape[0]\n",
        "    x0 = np.min(x0)\n",
        "    x1 = np.max(x1)\n",
        "    \n",
        "    if x1 > shape[1]:\n",
        "        # just went out of the image dimensions\n",
        "        raise ValueError(\"invalid RLE or image dimensions: x1=%d > shape[1]=%d\" % (\n",
        "            x1, shape[1]\n",
        "        ))\n",
        "\n",
        "    return x0, y0, x1, y1"
      ],
      "metadata": {
        "id": "a5kstsb_jSj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform ImageId into image path\n",
        "image_dir = '/content/drive/Shareddrives/DATA-255/Datasets/train/'\n",
        "train_df['ImageId'] = image_dir + train_df['ImageId'] + '.jpg'\n",
        "train_df.head()\n"
      ],
      "metadata": {
        "id": "0MCmB5B4jSnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create boxes list\n",
        "bboxes = [rle2bbox(c.EncodedPixels, (c.Height, c.Width)) for n, c in train_df.iterrows()]\n",
        "bboxes_array = np.array(bboxes)"
      ],
      "metadata": {
        "id": "AEUSs-Iijf4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.fillna(999)\n"
      ],
      "metadata": {
        "id": "wt-jK2RGjf7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add bounding boxes coordinates to train using detectron\n",
        "train_df['x0'], train_df['y0'], train_df['x1'], train_df['y1'] = bboxes_array[:,0], bboxes_array[:,1], bboxes_array[:,2], bboxes_array[:,3]\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "rYVOjT_zjf-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_array(value):\n",
        "    if isinstance(value, (np.ndarray, np.generic)):\n",
        "        return value\n",
        "    elif isinstance(value, str):\n",
        "        array = [int(val) for val in value.split(\",\")]\n",
        "    elif isinstance(value, int):\n",
        "        array = [999] \n",
        "    array = np.array(array)\n",
        "    return np.pad(array, (0, 14 - len(array)))"
      ],
      "metadata": {
        "id": "6ijsexpXjgAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform attribute string into tensor\n",
        "train_df[\"AttributesIds\"] = train_df[\"AttributesIds\"].map(transform_to_array)\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "wew_n8S0jgDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_pickle(\"train_df.pickle\")\n"
      ],
      "metadata": {
        "id": "3YzVXGixjgGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pycocotools\n",
        "def get_materialist_dicts(df):\n",
        "    \"\"\"\n",
        "    Transforms dataframe into dictionary used to train using detectron\n",
        "    \"\"\"\n",
        "    dataset_dicts = []\n",
        "    for idx, filename in enumerate(df[\"ImageId\"].unique()):\n",
        "        record = {}\n",
        "        # Get useful image information\n",
        "        height, width = df[df[\"ImageId\"] == filename][[\"Height\", \"Width\"]].values[0]\n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"image_id\"] = idx\n",
        "        record[\"height\"] = int(height)\n",
        "        record[\"width\"] = int(width)\n",
        "        \n",
        "        if idx % 1000 == 0:\n",
        "            print(idx)\n",
        "        \n",
        "        objs = []\n",
        "        for i, row in df[(df['ImageId'] == filename)].iterrows():\n",
        "            \n",
        "            # Get segmentation polygons\n",
        "            mask = rle_decode_string(row['EncodedPixels'], row['Height'], row['Width'])\n",
        "            # segmentation = pycocotools.mask.encode(np.asarray(mask, order=\"F\"))\n",
        "            contours, hierarchy = cv2.findContours((mask).astype(np.uint8), cv2.RETR_TREE,\n",
        "                                                    cv2.CHAIN_APPROX_SIMPLE)\n",
        "            segmentation = []\n",
        "\n",
        "            for contour in contours:\n",
        "                contour = contour.flatten().tolist()\n",
        "                if len(contour) > 4:\n",
        "                    segmentation.append(contour)\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [row['x0'], row['y0'], row['x1'], row['y1']],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": segmentation,\n",
        "                \"category_id\": row['ClassId'],\n",
        "                \"attributes\": row['AttributesIds'],\n",
        "                \"iscrowd\": 0,\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        \n",
        "        record['annotations'] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "\n",
        "# Use reduced dictionary to reduce the time to transform into dictionaries\n",
        "#df_copy = train_df[:8000].copy()\n",
        "\n",
        "df_copy = train_df.copy()\n",
        "\n",
        "df_copy = train_df[:23000].copy()\n",
        "df_copy_val = train_df[23000:24000].copy()\n",
        "\n",
        "# Full dictionary\n",
        "# df_copy = train_df.copy()\n",
        "\n",
        "materialist_dict = get_materialist_dicts(df_copy)\n"
      ],
      "metadata": {
        "id": "R4nOA9eDjgI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "materialist_dict[0].keys()\n"
      ],
      "metadata": {
        "id": "8Af4CdChjyEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_copy))\n",
        "print(len(materialist_dict))\n",
        "print(len(train_df))\n",
        "print(len(train_df[\"ImageId\"].unique()))\n",
        "print(len(df_copy[\"ImageId\"].unique()))"
      ],
      "metadata": {
        "id": "P9c3u084jyHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the custom dataset to detectron2,\n",
        "for d in [\"train\", \"val\"]:\n",
        "    if d == \"train\":\n",
        "        used_df = df_copy\n",
        "    else:\n",
        "        used_df = df_copy_val\n",
        "    DatasetCatalog.register(\"mat_\" + d, lambda df=used_df: get_materialist_dicts(df))\n",
        "    # DatasetCatalog.register(\"mat_\" + d, lambda df=df_copy: get_materialist_dicts(df))\n",
        "    MetadataCatalog.get(\"mat_\" + d).set(thing_classes=list(categories_df.name))\n",
        "materialist_metadata = MetadataCatalog.get(\"mat_train\")"
      ],
      "metadata": {
        "id": "4tlo4Bp_jyKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To verify the data loading is correct we visualize the annotations of randomly selected samples in the training set\n",
        "for d in random.sample(materialist_dict, 5):\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    img = mpimg.imread(d[\"file_name\"])\n",
        "    height, width = img.shape[:2]\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=materialist_metadata, scale=0.5)\n",
        "    visualizer._default_font_size = np.sqrt(height * width) // 20\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    plt.imshow(out.get_image()[:, :, ::-1])\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4vzEdZXUjyMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"0\"\n",
        "\n",
        "# Fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the dataset\n",
        "cfg_FPN = get_cfg()\n",
        "cfg_FPN.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg_FPN.DATASETS.TRAIN = (\"mat_train\",)\n",
        "cfg_FPN.DATASETS.TEST = (\"mat_val\",)\n",
        "cfg_FPN.DATALOADER.NUM_WORKERS = 1\n",
        "cfg_FPN.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg_FPN.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg_FPN.SOLVER.BASE_LR = 0.00025 \n",
        "cfg_FPN.SOLVER.MAX_ITER = 1000  \n",
        "cfg_FPN.SOLVER.STEPS = []       \n",
        "cfg_FPN.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  \n",
        "cfg_FPN.MODEL.ROI_HEADS.NUM_CLASSES = 46 \n",
        "\n",
        "# Train\n",
        "cfg_FPN.OUTPUT_DIR = \"./output_FPN\"\n",
        "os.makedirs(cfg_FPN.OUTPUT_DIR, exist_ok=True)\n",
        "trainer_FPN = DefaultTrainer(cfg_FPN) \n",
        "trainer_FPN.resume_or_load(resume=False)\n",
        "trainer_FPN.train()"
      ],
      "metadata": {
        "id": "3oP5wxvtj3hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create predictor from the weigths obtained during the training\n",
        "cfg_FPN.MODEL.WEIGHTS = os.path.join(cfg_FPN.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_FPN.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg_FPN.DATASETS.TEST = ('mat_val',)\n",
        "predictor_FPN = DefaultPredictor(cfg_FPN)"
      ],
      "metadata": {
        "id": "LEEoGmauj3kj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "plt.figure(figsize=(20,20))\n",
        "for d in random.sample(materialist_dict, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_FPN(im)\n",
        "    visualizer = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=materialist_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.imshow(v.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "cZh82j0ej3nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "\n",
        "# Show different images at random\n",
        "rows, cols = 3, 3\n",
        "plt.figure(figsize=(20,20))\n",
        "\n",
        "for i, d in enumerate(random.sample(materialist_dict, 9)):\n",
        "    # Process image\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Run through predictor\n",
        "    outputs = predictor_FPN(im)\n",
        "    \n",
        "    # Visualize\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=materialist_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.imshow(v.get_image()[:, :, ::-1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HJIIasLfjyPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "\n",
        "# Evaluate model\n",
        "evaluator_FPN = COCOEvaluator(\"mat_val\", output_dir=\"./output\")\n",
        "val_loader_FPN = build_detection_test_loader(cfg_FPN, \"mat_val\")"
      ],
      "metadata": {
        "id": "GXSnR7krkEin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_FPN = inference_on_dataset(predictor_FPN.model, val_loader_FPN, evaluator_FPN)\n"
      ],
      "metadata": {
        "id": "L2fxSGe9kEl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_FPN"
      ],
      "metadata": {
        "id": "qRAmQz5KkJKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
        "\n",
        "# Fine-tune a COCO-pretrained R50-DC5 Mask R-CNN model on the dataset\n",
        "cfg_DC5 = get_cfg()\n",
        "cfg_DC5.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml\"))\n",
        "cfg_DC5.DATASETS.TRAIN = (\"mat_train\",)\n",
        "cfg_DC5.DATASETS.TEST = ()\n",
        "cfg_DC5.DATALOADER.NUM_WORKERS = 1\n",
        "cfg_DC5.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_DC5_3x.yaml\")\n",
        "cfg_DC5.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg_DC5.SOLVER.BASE_LR = 0.00025  \n",
        "cfg_DC5.SOLVER.MAX_ITER = 1000 \n",
        "cfg_DC5.SOLVER.STEPS = []    \n",
        "cfg_DC5.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  \n",
        "cfg_DC5.MODEL.ROI_HEADS.NUM_CLASSES = 46  \n",
        "\n",
        "# Train\n",
        "cfg_DC5.OUTPUT_DIR = \"./output_DC5\"\n",
        "os.makedirs(cfg_DC5.OUTPUT_DIR, exist_ok=True)\n",
        "trainer_DC5 = DefaultTrainer(cfg_DC5) \n",
        "trainer_DC5.resume_or_load(resume=False)\n",
        "trainer_DC5.train()"
      ],
      "metadata": {
        "id": "ZzvsTT93kJM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cfg_DC5.MODEL.WEIGHTS = os.path.join(cfg_DC5.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_DC5.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set the testing threshold for this model\n",
        "cfg_DC5.DATASETS.TEST = ('mat_val')\n",
        "predictor_DC5 = DefaultPredictor(cfg_DC5)"
      ],
      "metadata": {
        "id": "-OQjFa-ckJPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "plt.figure(figsize=(20,20))\n",
        "for d in random.sample(materialist_dict, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_DC5(im)\n",
        "    visualizer = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=materialist_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.imshow(v.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "vkRn9QukkJR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show different images at random\n",
        "rows, cols = 3, 3\n",
        "plt.figure(figsize=(20,20))\n",
        "for i, d in enumerate(random.sample(materialist_dict, 9)):\n",
        "    # Process image\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Run through predictor\n",
        "    outputs = predictor_DC5(im)\n",
        "    \n",
        "    # Visualize\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=materialist_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.imshow(v.get_image()[:, :, ::-1])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "NAe0I4ygkEoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "evaluator_DC5 = COCOEvaluator(\"mat_val\", output_dir=cfg_DC5.OUTPUT_DIR)\n",
        "val_loader_DC5 = build_detection_test_loader(cfg_DC5, \"mat_val\")\n",
        "result_DC5 = inference_on_dataset(predictor_DC5.model, val_loader_DC5, evaluator_DC5)"
      ],
      "metadata": {
        "id": "gjNhAhdYkXRf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_DC5"
      ],
      "metadata": {
        "id": "e6adiqgvkXUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "# Fine-tune a COCO-pretrained R50-C4 Mask R-CNN model on the dataset\n",
        "cfg_C4 = get_cfg()\n",
        "cfg_C4.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml\"))\n",
        "cfg_C4.DATASETS.TRAIN = (\"mat_train\",)\n",
        "cfg_C4.DATASETS.TEST = ()\n",
        "cfg_C4.DATALOADER.NUM_WORKERS = 2\n",
        "cfg_C4.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_C4_3x.yaml\")\n",
        "cfg_C4.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg_C4.SOLVER.BASE_LR = 0.00025\n",
        "cfg_C4.SOLVER.MAX_ITER = 1000\n",
        "cfg_C4.SOLVER.STEPS = []\n",
        "cfg_C4.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
        "cfg_C4.MODEL.ROI_HEADS.NUM_CLASSES = 46\n",
        "\n",
        "# Train\n",
        "cfg_C4.OUTPUT_DIR = \"./output_C4\"\n",
        "os.makedirs(cfg_C4.OUTPUT_DIR, exist_ok=True)\n",
        "trainer_C4 = DefaultTrainer(cfg_C4) \n",
        "trainer_C4.resume_or_load(resume=False)\n",
        "trainer_C4.train()"
      ],
      "metadata": {
        "id": "qsG1QvSnkXXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create predictor from the weigths obtained during the training\n",
        "cfg_C4.MODEL.WEIGHTS = os.path.join(cfg_C4.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg_C4.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
        "cfg_C4.DATASETS.TEST = ('mat_val')\n",
        "predictor_C4 = DefaultPredictor(cfg_C4)"
      ],
      "metadata": {
        "id": "YcwwsA7gkgNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "plt.figure(figsize=(20,20))\n",
        "for d in random.sample(materialist_dict, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor_C4(im)\n",
        "    visualizer = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=materialist_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = visualizer.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.imshow(v.get_image()[:, :, ::-1])"
      ],
      "metadata": {
        "id": "s2fg0oVIkgOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show different images at random\n",
        "rows, cols = 3, 3\n",
        "plt.figure(figsize=(20,20))\n",
        "for i, d in enumerate(random.sample(materialist_dict, 9)):\n",
        "    # Process image\n",
        "    plt.subplot(rows, cols, i+1)\n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Run through predictor\n",
        "    outputs = predictor_C4(im)\n",
        "    \n",
        "    # Visualize\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=materialist_metadata, \n",
        "                   scale=0.8, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    plt.imshow(v.get_image()[:, :, ::-1])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_xRxjcRzkgRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator_C4 = COCOEvaluator(\"mat_val\", output_dir=\"./output\")\n",
        "val_loader_C4 = build_detection_test_loader(cfg_C4, \"mat_val\")\n",
        "result_C4 = inference_on_dataset(predictor_C4.model, val_loader_C4, evaluator_C4)"
      ],
      "metadata": {
        "id": "kFncCUEukgTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_C4"
      ],
      "metadata": {
        "id": "OV1jqe-Uk_kx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_dict = {}\n",
        "\n",
        "# Create table to compare results\n",
        "results_dict['bbox_DC5'] = result_DC5['bbox']\n",
        "results_dict['bbox_C4'] = result_C4['bbox']\n",
        "results_dict['bbox_FPN'] = result_FPN['bbox']\n",
        "results_dict['segm_DC5'] = result_DC5['segm']\n",
        "results_dict['segm_C4'] = result_C4['segm']\n",
        "results_dict['segm_FPN'] = result_FPN['segm']\n",
        "\n",
        "df_results = pd.DataFrame.from_dict(results_dict)\n",
        "df_results.loc[['AP', 'AP50', 'AP75', 'APs', 'APm', 'APl']]"
      ],
      "metadata": {
        "id": "dabO4EaKk_n1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "metrics = {}\n",
        "\n",
        "# Create losses plots\n",
        "for folder in [\"FPN\", \"C4\", \"DC5\"]:\n",
        "    with open(f'output_{folder}/metrics.json') as file:\n",
        "        lines = file.readlines()\n",
        "    \n",
        "    metrics_model = []\n",
        "    for line in lines:\n",
        "        metrics_model.append(ast.literal_eval(line))\n",
        "    metrics[folder] = metrics_model"
      ],
      "metadata": {
        "id": "OHp9-VUAk_qc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "FashionMaskRCNN_latest.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}